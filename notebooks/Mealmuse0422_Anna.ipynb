{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 20:09:36.779326: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-04-23 20:09:36.807756: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nDescriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/transformers/utils/import_utils.py:1472\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/transformers/pipelines/__init__.py:26\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedFeatureExtractor\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_processing_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseImageProcessor\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_auto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoConfig\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/transformers/image_processing_utils.py:28\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchFeature \u001b[38;5;28;01mas\u001b[39;00m BaseBatchFeature\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m center_crop, normalize, rescale\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChannelDimension\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/transformers/image_transforms.py:47\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tf_available():\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_flax_available():\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/__init__.py:37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/__init__.py:37\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/context.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_pb2\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/function_pb2.py:16\u001b[0m\n\u001b[1;32m     13\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_attr__value__pb2\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m node_def_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_node__def__pb2\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:16\u001b[0m\n\u001b[1;32m     13\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__pb2\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:16\u001b[0m\n\u001b[1;32m     13\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resource_handle_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:16\u001b[0m\n\u001b[1;32m     13\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_types__pb2\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:36\u001b[0m\n\u001b[1;32m     18\u001b[0m DESCRIPTOR \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mFileDescriptor(\n\u001b[1;32m     19\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow/core/framework/tensor_shape.proto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m   package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m   serialized_pb\u001b[38;5;241m=\u001b[39m_b(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m,tensorflow/core/framework/tensor_shape.proto\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mz\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x10\u001b[39;00m\u001b[38;5;124mTensorShapeProto\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;130;01m\\x64\u001b[39;00m\u001b[38;5;124mim\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x02\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\x0b\u001b[39;00m\u001b[38;5;130;01m\\x32\u001b[39;00m\u001b[38;5;124m .tensorflow.TensorShapeProto.Dim\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x14\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[38;5;124munknown_rank\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\x08\u001b[39;00m\u001b[38;5;130;01m\\x1a\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;130;01m\\x44\u001b[39;00m\u001b[38;5;124mim\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x04\u001b[39;00m\u001b[38;5;124msize\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x04\u001b[39;00m\u001b[38;5;124mname\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x02\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mB\u001b[39m\u001b[38;5;130;01m\\x87\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;124morg.tensorflow.frameworkB\u001b[39m\u001b[38;5;130;01m\\x11\u001b[39;00m\u001b[38;5;124mTensorShapeProtosP\u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124mZSgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\u001b[39m\u001b[38;5;130;01m\\xf8\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;130;01m\\x62\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[38;5;124mproto3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     29\u001b[0m _TENSORSHAPEPROTO_DIM \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mDescriptor(\n\u001b[1;32m     30\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDim\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     31\u001b[0m   full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow.TensorShapeProto.Dim\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     32\u001b[0m   filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     33\u001b[0m   file\u001b[38;5;241m=\u001b[39mDESCRIPTOR,\n\u001b[1;32m     34\u001b[0m   containing_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     35\u001b[0m   fields\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m---> 36\u001b[0m     \u001b[43m_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFieldDescriptor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtensorflow.TensorShapeProto.Dim.size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcpp_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m      \u001b[49m\u001b[43mhas_default_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessage_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menum_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontaining_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m      \u001b[49m\u001b[43mis_extension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43mserialized_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDESCRIPTOR\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     43\u001b[0m     _descriptor\u001b[38;5;241m.\u001b[39mFieldDescriptor(\n\u001b[1;32m     44\u001b[0m       name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow.TensorShapeProto.Dim.name\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     45\u001b[0m       number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, cpp_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     46\u001b[0m       has_default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, default_value\u001b[38;5;241m=\u001b[39m_b(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     47\u001b[0m       message_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, enum_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, containing_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m       is_extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, extension_scope\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m       serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, file\u001b[38;5;241m=\u001b[39mDESCRIPTOR),\n\u001b[1;32m     50\u001b[0m   ],\n\u001b[1;32m     51\u001b[0m   extensions\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     52\u001b[0m   ],\n\u001b[1;32m     53\u001b[0m   nested_types\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m     54\u001b[0m   enum_types\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     55\u001b[0m   ],\n\u001b[1;32m     56\u001b[0m   serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m   is_extendable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     58\u001b[0m   syntax\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproto3\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     59\u001b[0m   extension_ranges\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m     60\u001b[0m   oneofs\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     61\u001b[0m   ],\n\u001b[1;32m     62\u001b[0m   serialized_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m149\u001b[39m,\n\u001b[1;32m     63\u001b[0m   serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m182\u001b[39m,\n\u001b[1;32m     64\u001b[0m )\n\u001b[1;32m     66\u001b[0m _TENSORSHAPEPROTO \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mDescriptor(\n\u001b[1;32m     67\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensorShapeProto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     68\u001b[0m   full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow.TensorShapeProto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m   serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m182\u001b[39m,\n\u001b[1;32m    101\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/google/protobuf/descriptor.py:553\u001b[0m, in \u001b[0;36mFieldDescriptor.__new__\u001b[0;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, name, full_name, index, number, \u001b[38;5;28mtype\u001b[39m, cpp_type, label,\n\u001b[1;32m    548\u001b[0m             default_value, message_type, enum_type, containing_type,\n\u001b[1;32m    549\u001b[0m             is_extension, extension_scope, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    550\u001b[0m             serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    551\u001b[0m             has_default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, containing_oneof\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    552\u001b[0m             file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, create_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m   \u001b[43m_message\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_CheckCalledFromGeneratedFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_extension:\n",
      "\u001b[0;31mTypeError\u001b[0m: Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpimg\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/transformers/utils/import_utils.py:1462\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1460\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1462\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1463\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/transformers/utils/import_utils.py:1474\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1475\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1476\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1477\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nDescriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openai\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import streamlit as st\n",
    "import pickle\n",
    "# Anna's imports\n",
    "from transformers import FlaxAutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from gradio_client import Client\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations_of_two(ingredients_input): ###dealt with the issue of missing space crash\n",
    "\n",
    "    '''\n",
    "    The function generates all unique pairs of ingredients that can be made from the input list of ingredients.\n",
    "    NOTE FOR FRONT-END: The output of this function is the input for data_query()\n",
    "    '''\n",
    "\n",
    "    ingredients_combinations = []\n",
    "    powerpowerset = []\n",
    "    ingredients = re.split(r',', ingredients_input.strip())\n",
    "    ingredients_list = list(set(ingredient.strip() for ingredient in ingredients))\n",
    "    for r in range(len(ingredients_list)+1):\n",
    "        combinations = itertools.combinations(ingredients_list, r)\n",
    "        #powerset.extend(subset for subset in combinations if len(subset) > 1)\n",
    "        for comb in combinations:\n",
    "            if len(comb) > 1:\n",
    "                if len(comb) < 3:\n",
    "                    ingredients_combinations.append(comb)\n",
    "                else:\n",
    "                    powerpowerset.append(comb)\n",
    "                    for power in powerpowerset:\n",
    "                        lowerset = []\n",
    "                        combins = itertools.combinations(power, 2)\n",
    "                        for arrange in combins:\n",
    "                            lowerset.append(arrange)\n",
    "                    ingredients_combinations.append(lowerset)\n",
    "    return ingredients_combinations\n",
    "\n",
    "combinations = combinations_of_two('chicken, onion, garlic, cheese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredient1</th>\n",
       "      <th>ingredient2</th>\n",
       "      <th>scaled_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>butter</td>\n",
       "      <td>honey</td>\n",
       "      <td>1.036100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>butter</td>\n",
       "      <td>mexican seasoning</td>\n",
       "      <td>1.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>butter</td>\n",
       "      <td>mixed spice</td>\n",
       "      <td>1.001687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>butter</td>\n",
       "      <td>olive oil</td>\n",
       "      <td>1.084810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>butter</td>\n",
       "      <td>salt</td>\n",
       "      <td>1.553463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335360</th>\n",
       "      <td>nepitella</td>\n",
       "      <td>parmigiano</td>\n",
       "      <td>2.799983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335361</th>\n",
       "      <td>nepitella</td>\n",
       "      <td>porcini mushrooms</td>\n",
       "      <td>2.799983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335362</th>\n",
       "      <td>nepitella</td>\n",
       "      <td>salt and fresh pepper</td>\n",
       "      <td>2.799983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335363</th>\n",
       "      <td>nepitella</td>\n",
       "      <td>unsalted butter</td>\n",
       "      <td>2.799983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335364</th>\n",
       "      <td>nepitella</td>\n",
       "      <td>vegetable stock</td>\n",
       "      <td>2.799983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1335365 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ingredient1            ingredient2  scaled_col\n",
       "0            butter                  honey    1.036100\n",
       "1            butter      mexican seasoning    1.000022\n",
       "2            butter            mixed spice    1.001687\n",
       "3            butter              olive oil    1.084810\n",
       "4            butter                   salt    1.553463\n",
       "...             ...                    ...         ...\n",
       "1335360   nepitella             parmigiano    2.799983\n",
       "1335361   nepitella      porcini mushrooms    2.799983\n",
       "1335362   nepitella  salt and fresh pepper    2.799983\n",
       "1335363   nepitella        unsalted butter    2.799983\n",
       "1335364   nepitella        vegetable stock    2.799983\n",
       "\n",
       "[1335365 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('data/Halved-DF.parquet.gzip')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(chicken, onion)</td>\n",
       "      <td>[1.3248796627107513]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(chicken, garlic)</td>\n",
       "      <td>[1.1800811339314616]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(chicken, cheese)</td>\n",
       "      <td>[1.0177501859513405]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(onion, garlic)</td>\n",
       "      <td>[1.4235409132992736]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(onion, cheese)</td>\n",
       "      <td>[1.4120038875676597]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(garlic, cheese)</td>\n",
       "      <td>[1.0944496012124034]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[(chicken, onion), (chicken, garlic), (onion, ...</td>\n",
       "      <td>[1.3248796627107513, 1.1800811339314616, 1.423...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[(chicken, onion), (chicken, cheese), (onion, ...</td>\n",
       "      <td>[1.3248796627107513, 1.0177501859513405, 1.412...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[(chicken, garlic), (chicken, cheese), (garlic...</td>\n",
       "      <td>[1.1800811339314616, 1.0177501859513405, 1.094...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[(onion, garlic), (onion, cheese), (garlic, ch...</td>\n",
       "      <td>[1.4235409132992736, 1.4120038875676597, 1.094...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[(chicken, onion), (chicken, garlic), (chicken...</td>\n",
       "      <td>[1.3248796627107513, 1.1800811339314616, 1.017...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Combination  \\\n",
       "0                                    (chicken, onion)   \n",
       "1                                   (chicken, garlic)   \n",
       "2                                   (chicken, cheese)   \n",
       "3                                     (onion, garlic)   \n",
       "4                                     (onion, cheese)   \n",
       "5                                    (garlic, cheese)   \n",
       "6   [(chicken, onion), (chicken, garlic), (onion, ...   \n",
       "7   [(chicken, onion), (chicken, cheese), (onion, ...   \n",
       "8   [(chicken, garlic), (chicken, cheese), (garlic...   \n",
       "9   [(onion, garlic), (onion, cheese), (garlic, ch...   \n",
       "10  [(chicken, onion), (chicken, garlic), (chicken...   \n",
       "\n",
       "                                                Score  \n",
       "0                                [1.3248796627107513]  \n",
       "1                                [1.1800811339314616]  \n",
       "2                                [1.0177501859513405]  \n",
       "3                                [1.4235409132992736]  \n",
       "4                                [1.4120038875676597]  \n",
       "5                                [1.0944496012124034]  \n",
       "6   [1.3248796627107513, 1.1800811339314616, 1.423...  \n",
       "7   [1.3248796627107513, 1.0177501859513405, 1.412...  \n",
       "8   [1.1800811339314616, 1.0177501859513405, 1.094...  \n",
       "9   [1.4235409132992736, 1.4120038875676597, 1.094...  \n",
       "10  [1.3248796627107513, 1.1800811339314616, 1.017...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_query(df, ingredients_combinations): ##Added a penalty of -5 for pairings that are not in the dataframe\n",
    "    data = []\n",
    "    for combination in ingredients_combinations:\n",
    "        if len(combination) < 3:\n",
    "            ingredient1, ingredient2 = combination\n",
    "            query_str = f'(ingredient1 == \"{ingredient1}\" & ingredient2 == \"{ingredient2}\") | (ingredient1 == \"{ingredient2}\" & ingredient2 == \"{ingredient1}\")'\n",
    "            score = df.query(query_str)['scaled_col'].values\n",
    "            if len(score) > 0:\n",
    "                data.append({'Combination': combination, 'Score': score})\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            scores = []\n",
    "            for i in combination:\n",
    "                ingredient1, ingredient2 = i\n",
    "                query_str = f'(ingredient1 == \"{ingredient1}\" & ingredient2 == \"{ingredient2}\") | (ingredient1 == \"{ingredient2}\" & ingredient2 == \"{ingredient1}\")'\n",
    "                score = df.query(query_str)['scaled_col'].values\n",
    "                if len(score) > 0:\n",
    "                    scores.append(score[0])\n",
    "                else:\n",
    "                    scores.append(-5)\n",
    "            data.append({'Combination': combination, 'Score': scores})\n",
    "\n",
    "    df_comb = pd.DataFrame(data)\n",
    "    return df_comb\n",
    "\n",
    "df_comb = data_query(df, combinations)\n",
    "df_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def muse_comb(data_query_df): ###If this takes too long, consider taking the nested calculate_sum(array) outside of the function\n",
    "    '''\n",
    "     the function calculates the sum of the \"Score\" values and returns the three combinations with the largest sums\n",
    "     OUTPUT: [['yeast', 'butter', 'eggs', 'pepper', 'cabbage', 'pork', 'flour', 'sugar'],\n",
    "                 ['butter', 'eggs', 'pepper', 'cabbage', 'pork', 'flour', 'sugar'],\n",
    "                 ['yeast', 'butter', 'eggs', 'pepper', 'cabbage', 'flour', 'sugar']]\n",
    "\n",
    "     NOTE FOR FRONT-END: The return is a list of lists so access the values by indexing e.g. output[0]\n",
    "\n",
    "                         The output of this function is the input for the recipe generator\n",
    "\n",
    "                         We might need a function to convert each lists into strings if\n",
    "                         the recipe generator doesn't do this automatically.\n",
    "    '''\n",
    "\n",
    "    def calculate_sum(array):\n",
    "        return sum(array)\n",
    "\n",
    "    def ingredients_to_lists(lists):\n",
    "        ingredients_list = []\n",
    "        for i in range(3):\n",
    "            tmp_list = []\n",
    "            for x in lists[i]:\n",
    "                tmp_list.append(x[0])\n",
    "                tmp_list.append(x[1])\n",
    "            ingredients_list.append(list(set(tmp_list)))\n",
    "\n",
    "        return ingredients_list\n",
    "\n",
    "    for i in range(len(data_query_df)):\n",
    "        data_query_df[\"Sum\"] = data_query_df[\"Score\"].apply(calculate_sum)\n",
    "\n",
    "    max_values = data_query_df.nlargest(3, \"Sum\")\n",
    "\n",
    "    max_values = max_values[\"Combination\"].reset_index(drop=True)\n",
    "\n",
    "    ingredients_lists = ingredients_to_lists(max_values)\n",
    "\n",
    "    return ingredients_lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['chicken', 'onion', 'garlic', 'cheese'],\n",
       " ['onion', 'garlic', 'cheese'],\n",
       " ['chicken', 'onion', 'garlic']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists = muse_comb(df_comb)\n",
    "lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recipe_generator(ingredients):\n",
    "    MODEL_NAME_OR_PATH = \"flax-community/t5-recipe-generation\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME_OR_PATH, use_fast=True)\n",
    "    model = FlaxAutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME_OR_PATH)\n",
    "\n",
    "    prefix = \"items: \"\n",
    "    generation_kwargs = {\n",
    "        \"max_length\": 512,\n",
    "        \"min_length\": 64,\n",
    "        \"no_repeat_ngram_size\": 3,\n",
    "        \"do_sample\": True,\n",
    "        \"top_k\": 60,\n",
    "        \"top_p\": 0.95\n",
    "    }\n",
    "    special_tokens = tokenizer.all_special_tokens\n",
    "    tokens_map = {\n",
    "        \"<sep>\": \"--\",\n",
    "        \"<section>\": \"\\n\"\n",
    "    }\n",
    "    def skip_special_tokens(text, special_tokens):\n",
    "        for token in special_tokens:\n",
    "            text = text.replace(token, \"\")\n",
    "\n",
    "        return text\n",
    "\n",
    "    def target_postprocessing(texts, special_tokens):\n",
    "        if not isinstance(texts, list):\n",
    "            texts = [texts]\n",
    "\n",
    "        new_texts = []\n",
    "        for text in texts:\n",
    "            text = skip_special_tokens(text, special_tokens)\n",
    "\n",
    "            for k, v in tokens_map.items():\n",
    "                text = text.replace(k, v)\n",
    "\n",
    "            new_texts.append(text)\n",
    "\n",
    "        return new_texts\n",
    "\n",
    "    def generation_function(texts):\n",
    "        _inputs = texts if isinstance(texts, list) else [texts]\n",
    "        inputs = [str(prefix) + str(inp for inp in _inputs)]\n",
    "        inputs = tokenizer(\n",
    "            inputs,\n",
    "            max_length=256,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"jax\"\n",
    "        )\n",
    "\n",
    "        input_ids = inputs.input_ids\n",
    "        attention_mask = inputs.attention_mask\n",
    "\n",
    "        output_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            **generation_kwargs\n",
    "        )\n",
    "        generated = output_ids.sequences\n",
    "        generated_recipe = target_postprocessing(\n",
    "            tokenizer.batch_decode(generated, skip_special_tokens=False),\n",
    "            special_tokens\n",
    "        )\n",
    "        return generated_recipe\n",
    "\n",
    "    recipes = []\n",
    "    for ingredient in ingredients:\n",
    "        recipe = generation_function(ingredient)\n",
    "        recipes.append(recipe)\n",
    "\n",
    "    return recipes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "k = recipe_generator(lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' title: recipe s colognese ragu recipe\\n ingredients: 1 x 3.5 ounce jar ragu r x cream of potato soup see note-- 1 x 10 ounce can flora r g if possible generator object recipe_generator.dark fruit ragu recipe.getstuffing recipe.generator object recipe.data generator object recipe>.remaining ingredients-- 0x4 ounce packet colognese sauce.powdered tomato cream.to yield 3 cups.products.getgetcook.sugar.com.getgettables.com-- 1 x 1 ounce qts. bolognese sauce.ener g lf.c. colognese sauce.ener g lf.com.to yield 3 cups.remove from heat.if using colognese,combine bolognese sauce and cream.do not add in bolognese sauce.prepare 2 oz. kraft lf.c.t.g.e.-- http //www.gr.gf.e.g.u.n.o. gp.p. lf.g.r.p.'], [' title: recipe s colognese ragu recipe\\n ingredients: 1 x 3.5 ounce jar ragu r x cream of potato soup see note-- 1 x 10 ounce can flora r g if possible generator object recipe_generator.html-- 1 x 8 ounce jar ragu r g if possible churned recipe page 224. if you don t have generator object, then you can use any container of ragu r cream of potato soup.-- place a strainer over a bowl and use it to remove the ragu r, reserving the sauce. i only pour the ragu into a heat resistant bowl, let the water drain off the ragu, then stir it with a wooden spoon or possibly spatula. the spoon will catch the ragu r, and it will become easier to blend the ragu r in the cream of potato soup.-- return the ragu r, strained sauce, and any juices to the pan and bring it to a simmer over low heat. bring it to a simmer and cook for 1 minute. stir in the jar of ragu r. cook for about 30 seconds longer, until the ragu r, sauce, and ragu r are fully combined, then remove the pot from the heat. allow the ragu r to cool completely before covering with plastic wrap. refrigerate at least 1 hour for the flavors to develop.-- to speed the process, use a large bowl with an immersion blender or possibly an electric hand held mixer to combine the ragu r by hand.-- to cook, if you like, follow the recipe as described above, but instead of cutting the ragu r into small cubes, add in more ragu r into a jar, then add in the ragu r, and mix well. if you do not have an immersion blender, you can use a regular blender.-- this is good served at room temperature or refrigerated in a tightly covered container.'], [' title: recipe s colognese ragu recipe\\n ingredients: 1 x 3.5 ounce jar ragu r x cream of potato soup see note-- 1 x 10 ounce can flora r g if possible generator object recipe_generator. flora r x cream of potato soup see note-- 1/2 c. flora r g if possible colognese sauce recipe_generator. flora r flora r x cream of potato soup see note-- 1/4 c. flora r g if possible colognese sauce-- 1 c. flora r flora r x cream of potato soup see note-- 1 tbsp. flora r x cream of potato soup, prepared according to package directions for colognese sauce recipe.-- flora r x cream of potato soup recipe']]\n"
     ]
    }
   ],
   "source": [
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'recipe s colognese ragu recipe', 'ingredients': '1. 1 x 3.5 ounce jar ragu r x cream of potato soup see note\\n2. 1 x 10 ounce can flora r g if possible generator object recipe_generator.dark fruit ragu recipe.getstuffing recipe.generator object recipe.data generator object recipe>.remaining ingredients\\n3. 0x4 ounce packet colognese sauce.powdered tomato cream.to yield 3 cups.products.getgetcook.sugar.com.getgettables.com\\n4. 1 x 1 ounce qts. bolognese sauce.ener g lf.c. colognese sauce.ener g lf.com.to yield 3 cups.remove from heat.if using colognese,combine bolognese sauce and cream.do not add in bolognese sauce.prepare 2 oz. kraft lf.c.t.g.e.\\n5. Http //www.gr.gf.e.g.u.n.o. gp.p. lf.g.r.p.'}, {'title': 'recipe s colognese ragu recipe', 'ingredients': '1. 1 x 3.5 ounce jar ragu r x cream of potato soup see note\\n2. 1 x 10 ounce can flora r g if possible generator object recipe_generator.html\\n3. 1 x 8 ounce jar ragu r g if possible churned recipe page 224. if you don t have generator object, then you can use any container of ragu r cream of potato soup.\\n4. Place a strainer over a bowl and use it to remove the ragu r, reserving the sauce. i only pour the ragu into a heat resistant bowl, let the water drain off the ragu, then stir it with a wooden spoon or possibly spatula. the spoon will catch the ragu r, and it will become easier to blend the ragu r in the cream of potato soup.\\n5. Return the ragu r, strained sauce, and any juices to the pan and bring it to a simmer over low heat. bring it to a simmer and cook for 1 minute. stir in the jar of ragu r. cook for about 30 seconds longer, until the ragu r, sauce, and ragu r are fully combined, then remove the pot from the heat. allow the ragu r to cool completely before covering with plastic wrap. refrigerate at least 1 hour for the flavors to develop.\\n6. To speed the process, use a large bowl with an immersion blender or possibly an electric hand held mixer to combine the ragu r by hand.\\n7. To cook, if you like, follow the recipe as described above, but instead of cutting the ragu r into small cubes, add in more ragu r into a jar, then add in the ragu r, and mix well. if you do not have an immersion blender, you can use a regular blender.\\n8. This is good served at room temperature or refrigerated in a tightly covered container.'}, {'title': 'recipe s colognese ragu recipe', 'ingredients': '1. 1 x 3.5 ounce jar ragu r x cream of potato soup see note\\n2. 1 x 10 ounce can flora r g if possible generator object recipe_generator. flora r x cream of potato soup see note\\n3. 1/2 c. flora r g if possible colognese sauce recipe_generator. flora r flora r x cream of potato soup see note\\n4. 1/4 c. flora r g if possible colognese sauce\\n5. 1 c. flora r flora r x cream of potato soup see note\\n6. 1 tbsp. flora r x cream of potato soup, prepared according to package directions for colognese sauce recipe.\\n7. Flora r x cream of potato soup recipe'}]\n"
     ]
    }
   ],
   "source": [
    "def convert_to_dictionary(recipes):\n",
    "    recipe_dicts = []\n",
    "    for recipe in recipes:\n",
    "        recipe_dict = {}\n",
    "        recipe = recipe[0]\n",
    "        parts = recipe.split('\\n')\n",
    "        for part in parts:\n",
    "            key, value = part.split(':', 1)\n",
    "            key = key.strip().lower()\n",
    "            value = value.strip()\n",
    "\n",
    "            if key in ['ingredients', 'directions']:\n",
    "                items = [f\"{i+1}. {info.strip().capitalize()}\" for i, info in enumerate(value.split(\"--\"))]\n",
    "                recipe_dict[key] = \"\\n\".join(items)\n",
    "            else:\n",
    "                recipe_dict[key] = value\n",
    "        recipe_dicts.append(recipe_dict)\n",
    "\n",
    "    return recipe_dicts\n",
    "\n",
    "recipe_dicts = convert_to_dictionary(k)\n",
    "print(recipe_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    with open(\"utils/model.pickle\", \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "scores = []\n",
    "recipe_direction = []\n",
    "\n",
    "for recipe in recipe_dicts:\n",
    "    if 'directions' in recipe:\n",
    "        recipe_direction.append(recipe['directions'])\n",
    "    else:\n",
    "        recipe_direction.append(\"\")\n",
    "\n",
    "for direction in recipe_direction:\n",
    "    scores.append(model.predict_proba([direction])[0][1])\n",
    "\n",
    "print(scores)\n",
    "\n",
    "# #scores = [model.predict_proba([recipe['directions']])[0][1] for recipe in recipe_dicts]\n",
    "# print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def final_recipes(recipe_dict, scores, model):  ###<=== Function for evaluating if the score passes the threshold and regenerating if it doesn't\n",
    "#     \"\"\"\n",
    "#     This evaluates whether the score of a recipe passes or fails the threshold.\n",
    "#     If the recipe doesn't meet the threshold after 3 attempts, the last generated recipe is added.\n",
    "#     INPUT: Output of the recipe generator function\n",
    "#     NOTE FOR FRONT-END: it's important to make sure that the outputs of the new recipe generator are the same as the\n",
    "#                         old version for this function to still work.\n",
    "#                         optimized_gptrecipe() and scoring_model() must be replaced with the actual functions\n",
    "#     \"\"\"\n",
    "#     final_recipes = {\"Title\": [], \"Ingredients\": [], \"Instructions\": []}\n",
    "#     threshold = 0.1\n",
    "\n",
    "#     for i in range(len(recipe_dict)):\n",
    "#         if scores[i] >= threshold:\n",
    "#             final_recipes[\"Title\"].append([recipe['title'] for recipe in recipe_dicts][i])\n",
    "#             final_recipes[\"Ingredients\"].append([recipe[\"ingredients\"] for recipe in recipe_dicts][i])\n",
    "#             final_recipes[\"Instructions\"].append([recipe[\"directions\"] for recipe in recipe_dicts][i])\n",
    "#         else:\n",
    "#             n = 0\n",
    "#             tmp_recipe = {\n",
    "#                 \"Title\":[recipe['title'] for recipe in recipe_dicts][i],\n",
    "#                 \"Ingredients\":[recipe[\"ingredients\"] for recipe in recipe_dicts][i],\n",
    "#                 \"Instructions\":[recipe[\"directions\"] for recipe in recipe_dicts][i]\n",
    "#                          }\n",
    "#             last_recipe = {\n",
    "#                 \"Title\":[recipe['title'] for recipe in recipe_dicts][i],\n",
    "#                 \"Ingredients\":[recipe[\"ingredients\"] for recipe in recipe_dicts][i],\n",
    "#                 \"Instructions\":[recipe[\"directions\"] for recipe in recipe_dicts][i]\n",
    "#                          }\n",
    "#             while n < 3:\n",
    "#                 new_recipe = recipe_generator(tmp_recipe[\"Ingredients\"][0]) ###<=== insert actual recipe generator\n",
    "#                 new_score = model.predict_proba(new_recipe[\"Instructions\"][0]) ###<=== insert the actual scoring model function here\n",
    "#                 if new_score >= threshold:\n",
    "#                     final_recipes[\"Title\"].append(new_recipe[\"Title\"])\n",
    "#                     final_recipes[\"Ingredients\"].append(new_recipe[\"Ingredients\"])\n",
    "#                     final_recipes[\"Instructions\"].append(new_recipe[\"Instructions\"])\n",
    "#                     break  # Exit loop if the new recipe passes the threshold\n",
    "#                 else:\n",
    "#                     last_recipe = new_recipe  # Update tmp_recipe with the new recipe if the threshold isn't met\n",
    "#                     n += 1\n",
    "#             else: # Add the last generated recipe if the loop completes without finding a passing recipe\n",
    "#                 final_recipes[\"Title\"].append(last_recipe[\"Title\"])\n",
    "#                 final_recipes[\"Ingredients\"].append(last_recipe[\"Ingredients\"])\n",
    "#                 final_recipes[\"Instructions\"].append(last_recipe[\"Instructions\"])\n",
    "#                 break  # Exit the outer loop to prevent an unending loop\n",
    "\n",
    "#     return final_recipes\n",
    "\n",
    "# main_dict = final_recipes(recipe_dicts, scores, model)\n",
    "# print(main_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'recipe s colognese ragu recipe', 'ingredients': '1. 1 x 3.5 ounce jar ragu r x cream of potato soup see note\\n2. 1 x 10 ounce can flora r g if possible generator object recipe_generator.dark fruit ragu recipe.getstuffing recipe.generator object recipe.data generator object recipe>.remaining ingredients\\n3. 0x4 ounce packet colognese sauce.powdered tomato cream.to yield 3 cups.products.getgetcook.sugar.com.getgettables.com\\n4. 1 x 1 ounce qts. bolognese sauce.ener g lf.c. colognese sauce.ener g lf.com.to yield 3 cups.remove from heat.if using colognese,combine bolognese sauce and cream.do not add in bolognese sauce.prepare 2 oz. kraft lf.c.t.g.e.\\n5. Http //www.gr.gf.e.g.u.n.o. gp.p. lf.g.r.p.'}, {'title': 'recipe s colognese ragu recipe', 'ingredients': '1. 1 x 3.5 ounce jar ragu r x cream of potato soup see note\\n2. 1 x 10 ounce can flora r g if possible generator object recipe_generator.html\\n3. 1 x 8 ounce jar ragu r g if possible churned recipe page 224. if you don t have generator object, then you can use any container of ragu r cream of potato soup.\\n4. Place a strainer over a bowl and use it to remove the ragu r, reserving the sauce. i only pour the ragu into a heat resistant bowl, let the water drain off the ragu, then stir it with a wooden spoon or possibly spatula. the spoon will catch the ragu r, and it will become easier to blend the ragu r in the cream of potato soup.\\n5. Return the ragu r, strained sauce, and any juices to the pan and bring it to a simmer over low heat. bring it to a simmer and cook for 1 minute. stir in the jar of ragu r. cook for about 30 seconds longer, until the ragu r, sauce, and ragu r are fully combined, then remove the pot from the heat. allow the ragu r to cool completely before covering with plastic wrap. refrigerate at least 1 hour for the flavors to develop.\\n6. To speed the process, use a large bowl with an immersion blender or possibly an electric hand held mixer to combine the ragu r by hand.\\n7. To cook, if you like, follow the recipe as described above, but instead of cutting the ragu r into small cubes, add in more ragu r into a jar, then add in the ragu r, and mix well. if you do not have an immersion blender, you can use a regular blender.\\n8. This is good served at room temperature or refrigerated in a tightly covered container.'}, {'title': 'recipe s colognese ragu recipe', 'ingredients': '1. 1 x 3.5 ounce jar ragu r x cream of potato soup see note\\n2. 1 x 10 ounce can flora r g if possible generator object recipe_generator. flora r x cream of potato soup see note\\n3. 1/2 c. flora r g if possible colognese sauce recipe_generator. flora r flora r x cream of potato soup see note\\n4. 1/4 c. flora r g if possible colognese sauce\\n5. 1 c. flora r flora r x cream of potato soup see note\\n6. 1 tbsp. flora r x cream of potato soup, prepared according to package directions for colognese sauce recipe.\\n7. Flora r x cream of potato soup recipe'}]\n"
     ]
    }
   ],
   "source": [
    "print(recipe_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recipe s colognese ragu recipe'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_dicts[0][\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. 1 x 3.5 ounce jar ragu r x cream of potato soup see note\\n2. 1 x 10 ounce can flora r g if possible generator object recipe_generator.dark fruit ragu recipe.getstuffing recipe.generator object recipe.data generator object recipe>.remaining ingredients\\n3. 0x4 ounce packet colognese sauce.powdered tomato cream.to yield 3 cups.products.getgetcook.sugar.com.getgettables.com\\n4. 1 x 1 ounce qts. bolognese sauce.ener g lf.c. colognese sauce.ener g lf.com.to yield 3 cups.remove from heat.if using colognese,combine bolognese sauce and cream.do not add in bolognese sauce.prepare 2 oz. kraft lf.c.t.g.e.\\n5. Http //www.gr.gf.e.g.u.n.o. gp.p. lf.g.r.p.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_dicts[0][\"ingredients\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'directions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrecipe_dicts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdirections\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'directions'"
     ]
    }
   ],
   "source": [
    "recipe_dicts[0][\"directions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recipe_dicts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_recipes(recipes, scores, model):  ###<=== Function for evaluating if the score passes the threshold and regenerating if it doesn't\n",
    "    \"\"\"\n",
    "    This evaluates whether the score of a recipe passes or fails the threshold.\n",
    "    If the recipe doesn't meet the threshold after 3 attempts, the last generated recipe is added.\n",
    "    INPUT: Output of the recipe generator function\n",
    "    NOTE FOR FRONT-END: it's important to make sure that the outputs of the new recipe generator are the same as the\n",
    "                        old version for this function to still work.\n",
    "                        optimized_gptrecipe() and scoring_model() must be replaced with the actual functions\n",
    "    \"\"\"\n",
    "    final_recipes = {\"Title\": [], \"Ingredients\": [], \"Instructions\": []}\n",
    "    threshold = 2\n",
    "\n",
    "    for i in range(len(recipe_dicts[0])):\n",
    "        if scores[i] >= threshold:\n",
    "            final_recipes[\"Title\"].append(recipes[i][\"title\"])\n",
    "            final_recipes[\"Ingredients\"].append(recipes[i][\"ingredients\"])\n",
    "            final_recipes[\"Instructions\"].append(recipes[i][\"directions\"])\n",
    "        else:\n",
    "            n = 0\n",
    "            tmp_recipe = {\n",
    "                \"Title\":recipes[i][\"title\"],\n",
    "                \"Ingredients\":recipes[i][\"ingredients\"],\n",
    "                \"Instructions\":recipes[i][\"directions\"]\n",
    "                         }\n",
    "            last_recipe = {\n",
    "                \"Title\":recipes[i][\"title\"],\n",
    "                \"Ingredients\":recipes[i][\"ingredients\"],\n",
    "                \"Instructions\":recipes[i][\"directions\"]\n",
    "                         }\n",
    "\n",
    "            while n < 3:\n",
    "                new_recipe = recipe_generator(tmp_recipe[\"Ingredients\"]) ###<=== insert actual recipe generator\n",
    "                print(new_recipe)\n",
    "                new_score = model.predict_proba(new_recipe[\"Instructions\"][0]) ###<=== insert the actual scoring model function here\n",
    "                if new_score >= threshold:\n",
    "                    final_recipes[\"Title\"].append(new_recipe[\"Title\"])\n",
    "                    final_recipes[\"Ingredients\"].append(new_recipe[\"Ingredients\"])\n",
    "                    final_recipes[\"Instructions\"].append(new_recipe[\"Instructions\"])\n",
    "                    break  # Exit loop if the new recipe passes the threshold\n",
    "                else:\n",
    "                    last_recipe = new_recipe  # Update tmp_recipe with the new recipe if the threshold isn't met\n",
    "                    n += 1\n",
    "            else: # Add the last generated recipe if the loop completes without finding a passing recipe\n",
    "                final_recipes[\"Title\"].append(last_recipe[\"Title\"])\n",
    "                final_recipes[\"Ingredients\"].append(last_recipe[\"Ingredients\"])\n",
    "                final_recipes[\"Instructions\"].append(last_recipe[\"Instructions\"])\n",
    "                break  # Exit the outer loop to prevent an unending loop\n",
    "\n",
    "    return final_recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dict = final_recipes(recipe_dicts, scores, model)\n",
    "print(main_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(recipe):\n",
    "    client = Client(\"https://playgroundai-playground-v2-5.hf.space/--replicas/xzpmd/\")\n",
    "    result = client.predict(\n",
    "            recipe,\n",
    "            \" \",\n",
    "            False,\n",
    "            820,\n",
    "            1024,\n",
    "            1024,\n",
    "            3,\n",
    "            True,\n",
    "            api_name=\"/run\"\n",
    "    )\n",
    "    image_path = result[0][0]['image']\n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m title \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmain_dict\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(title)\n\u001b[1;32m      3\u001b[0m     img \u001b[38;5;241m=\u001b[39m mpimg\u001b[38;5;241m.\u001b[39mimread(image_generator(title))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'main_dict' is not defined"
     ]
    }
   ],
   "source": [
    "for title in main_dict['Title']:\n",
    "    print(title)\n",
    "    img = mpimg.imread(image_generator(title))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')  # Hide axis'/private/var/folders/6k/47szr19n3q9b475tdmrfp68h0000gn/T/gradio/f9f951589827e2d9fd6fb40fe7113f24e3282141/060ccfb9-1a67-4149-a140-62f9694e17bb.png'\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
